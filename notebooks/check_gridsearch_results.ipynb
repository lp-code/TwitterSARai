{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-22T20:46:50.423695Z",
     "start_time": "2020-02-22T20:46:48.357648Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-22T20:46:53.160443Z",
     "start_time": "2020-02-22T20:46:50.466614Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lpesch\\AppData\\Local\\Continuum\\anaconda3\\envs\\fastai\\lib\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator MultinomialNB from version 0.22 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "C:\\Users\\lpesch\\AppData\\Local\\Continuum\\anaconda3\\envs\\fastai\\lib\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator ComplementNB from version 0.22 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "C:\\Users\\lpesch\\AppData\\Local\\Continuum\\anaconda3\\envs\\fastai\\lib\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator SGDClassifier from version 0.22 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "C:\\Users\\lpesch\\AppData\\Local\\Continuum\\anaconda3\\envs\\fastai\\lib\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator CountVectorizer from version 0.22 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "C:\\Users\\lpesch\\AppData\\Local\\Continuum\\anaconda3\\envs\\fastai\\lib\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator TfidfTransformer from version 0.22 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "C:\\Users\\lpesch\\AppData\\Local\\Continuum\\anaconda3\\envs\\fastai\\lib\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator TfidfVectorizer from version 0.22 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "with open(\"..\\grid_search_results2.pck\", \"rb\") as f:\n",
    "    gridsearch_results = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-22T20:46:58.455767Z",
     "start_time": "2020-02-22T20:46:58.444768Z"
    }
   },
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(gridsearch_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-22T20:51:03.126273Z",
     "start_time": "2020-02-22T20:51:03.069144Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_clf__estimator</th>\n",
       "      <th>param_clf__threshold</th>\n",
       "      <th>param_prep__remove_punctuation</th>\n",
       "      <th>param_prep__remove_stopwords</th>\n",
       "      <th>param_prep__stem</th>\n",
       "      <th>param_vect</th>\n",
       "      <th>...</th>\n",
       "      <th>param_vect__ngram_range</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>1.055201</td>\n",
       "      <td>0.016677</td>\n",
       "      <td>0.261199</td>\n",
       "      <td>0.008751</td>\n",
       "      <td>MultinomialNB(alpha=1, class_prior=None, fit_p...</td>\n",
       "      <td>0.6</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>...</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>{'clf__estimator': MultinomialNB(alpha=1, clas...</td>\n",
       "      <td>0.859155</td>\n",
       "      <td>0.928105</td>\n",
       "      <td>0.891720</td>\n",
       "      <td>0.891720</td>\n",
       "      <td>0.920635</td>\n",
       "      <td>0.898267</td>\n",
       "      <td>0.024520</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690</th>\n",
       "      <td>0.929000</td>\n",
       "      <td>0.040739</td>\n",
       "      <td>0.233800</td>\n",
       "      <td>0.015367</td>\n",
       "      <td>SGDClassifier(alpha=0.001, average=False, clas...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>TfidfVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>...</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>{'clf__estimator': SGDClassifier(alpha=0.001, ...</td>\n",
       "      <td>0.859060</td>\n",
       "      <td>0.928105</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.887417</td>\n",
       "      <td>0.910448</td>\n",
       "      <td>0.897006</td>\n",
       "      <td>0.023189</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810</th>\n",
       "      <td>0.937800</td>\n",
       "      <td>0.033524</td>\n",
       "      <td>0.240599</td>\n",
       "      <td>0.017917</td>\n",
       "      <td>SGDClassifier(alpha=0.001, average=False, clas...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>TfidfVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>...</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>{'clf__estimator': SGDClassifier(alpha=0.001, ...</td>\n",
       "      <td>0.859060</td>\n",
       "      <td>0.928105</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.887417</td>\n",
       "      <td>0.910448</td>\n",
       "      <td>0.897006</td>\n",
       "      <td>0.023189</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>0.880853</td>\n",
       "      <td>0.022291</td>\n",
       "      <td>0.233722</td>\n",
       "      <td>0.009932</td>\n",
       "      <td>ComplementNB(alpha=1, class_prior=None, fit_pr...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>...</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>{'clf__estimator': ComplementNB(alpha=1, class...</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.897436</td>\n",
       "      <td>0.920245</td>\n",
       "      <td>0.884848</td>\n",
       "      <td>0.924242</td>\n",
       "      <td>0.896783</td>\n",
       "      <td>0.024571</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>1.070803</td>\n",
       "      <td>0.033658</td>\n",
       "      <td>0.250397</td>\n",
       "      <td>0.026869</td>\n",
       "      <td>MultinomialNB(alpha=1, class_prior=None, fit_p...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>...</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>{'clf__estimator': MultinomialNB(alpha=1, clas...</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.913580</td>\n",
       "      <td>0.884848</td>\n",
       "      <td>0.924242</td>\n",
       "      <td>0.896608</td>\n",
       "      <td>0.023628</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>0.861849</td>\n",
       "      <td>0.035064</td>\n",
       "      <td>0.220401</td>\n",
       "      <td>0.010366</td>\n",
       "      <td>ComplementNB(alpha=1, class_prior=None, fit_pr...</td>\n",
       "      <td>0.6</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>...</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>{'clf__estimator': ComplementNB(alpha=1, class...</td>\n",
       "      <td>0.859155</td>\n",
       "      <td>0.928105</td>\n",
       "      <td>0.886076</td>\n",
       "      <td>0.886076</td>\n",
       "      <td>0.920635</td>\n",
       "      <td>0.896009</td>\n",
       "      <td>0.025267</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "108       1.055201      0.016677         0.261199        0.008751   \n",
       "690       0.929000      0.040739         0.233800        0.015367   \n",
       "810       0.937800      0.033524         0.240599        0.017917   \n",
       "302       0.880853      0.022291         0.233722        0.009932   \n",
       "62        1.070803      0.033658         0.250397        0.026869   \n",
       "348       0.861849      0.035064         0.220401        0.010366   \n",
       "\n",
       "                                  param_clf__estimator param_clf__threshold  \\\n",
       "108  MultinomialNB(alpha=1, class_prior=None, fit_p...                  0.6   \n",
       "690  SGDClassifier(alpha=0.001, average=False, clas...                  0.5   \n",
       "810  SGDClassifier(alpha=0.001, average=False, clas...                  0.5   \n",
       "302  ComplementNB(alpha=1, class_prior=None, fit_pr...                  0.4   \n",
       "62   MultinomialNB(alpha=1, class_prior=None, fit_p...                  0.4   \n",
       "348  ComplementNB(alpha=1, class_prior=None, fit_pr...                  0.6   \n",
       "\n",
       "    param_prep__remove_punctuation param_prep__remove_stopwords  \\\n",
       "108                           True                         True   \n",
       "690                           True                         True   \n",
       "810                           True                         True   \n",
       "302                           True                         True   \n",
       "62                            True                         True   \n",
       "348                           True                         True   \n",
       "\n",
       "    param_prep__stem                                         param_vect  ...  \\\n",
       "108             True  CountVectorizer(analyzer='word', binary=False,...  ...   \n",
       "690             True  TfidfVectorizer(analyzer='word', binary=False,...  ...   \n",
       "810             True  TfidfVectorizer(analyzer='word', binary=False,...  ...   \n",
       "302             True  CountVectorizer(analyzer='word', binary=False,...  ...   \n",
       "62              True  CountVectorizer(analyzer='word', binary=False,...  ...   \n",
       "348             True  CountVectorizer(analyzer='word', binary=False,...  ...   \n",
       "\n",
       "    param_vect__ngram_range  \\\n",
       "108                  (1, 1)   \n",
       "690                  (1, 1)   \n",
       "810                  (1, 1)   \n",
       "302                  (1, 1)   \n",
       "62                   (1, 1)   \n",
       "348                  (1, 1)   \n",
       "\n",
       "                                                params split0_test_score  \\\n",
       "108  {'clf__estimator': MultinomialNB(alpha=1, clas...          0.859155   \n",
       "690  {'clf__estimator': SGDClassifier(alpha=0.001, ...          0.859060   \n",
       "810  {'clf__estimator': SGDClassifier(alpha=0.001, ...          0.859060   \n",
       "302  {'clf__estimator': ComplementNB(alpha=1, class...          0.857143   \n",
       "62   {'clf__estimator': MultinomialNB(alpha=1, clas...          0.857143   \n",
       "348  {'clf__estimator': ComplementNB(alpha=1, class...          0.859155   \n",
       "\n",
       "     split1_test_score  split2_test_score  split3_test_score  \\\n",
       "108           0.928105           0.891720           0.891720   \n",
       "690           0.928105           0.900000           0.887417   \n",
       "810           0.928105           0.900000           0.887417   \n",
       "302           0.897436           0.920245           0.884848   \n",
       "62            0.903226           0.913580           0.884848   \n",
       "348           0.928105           0.886076           0.886076   \n",
       "\n",
       "     split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "108           0.920635         0.898267        0.024520                1  \n",
       "690           0.910448         0.897006        0.023189                2  \n",
       "810           0.910448         0.897006        0.023189                2  \n",
       "302           0.924242         0.896783        0.024571                4  \n",
       "62            0.924242         0.896608        0.023628                5  \n",
       "348           0.920635         0.896009        0.025267                6  \n",
       "\n",
       "[6 rows x 21 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.sort_values(by=\"rank_test_score\", ascending=True).head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T21:21:03.783834Z",
     "start_time": "2020-01-13T21:21:03.770837Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lpesch\\AppData\\Local\\Continuum\\anaconda3\\envs\\fastai\\lib\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator LinearSVC from version 0.22 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "C:\\Users\\lpesch\\AppData\\Local\\Continuum\\anaconda3\\envs\\fastai\\lib\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator MultinomialNB from version 0.22 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "C:\\Users\\lpesch\\AppData\\Local\\Continuum\\anaconda3\\envs\\fastai\\lib\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator ComplementNB from version 0.22 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "C:\\Users\\lpesch\\AppData\\Local\\Continuum\\anaconda3\\envs\\fastai\\lib\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator SGDClassifier from version 0.22 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "C:\\Users\\lpesch\\AppData\\Local\\Continuum\\anaconda3\\envs\\fastai\\lib\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator CountVectorizer from version 0.22 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "C:\\Users\\lpesch\\AppData\\Local\\Continuum\\anaconda3\\envs\\fastai\\lib\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator TfidfTransformer from version 0.22 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "C:\\Users\\lpesch\\AppData\\Local\\Continuum\\anaconda3\\envs\\fastai\\lib\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator TfidfVectorizer from version 0.22 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "with open(\"..\\grid_search_results2.pck\", \"rb\") as f:\n",
    "    gridsearch_results = pickle.load(f)\n",
    "df2 = pd.DataFrame(gridsearch_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T21:21:07.697834Z",
     "start_time": "2020-01-13T21:21:07.568834Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_clf__estimator</th>\n",
       "      <th>param_prep__remove_punctuation</th>\n",
       "      <th>param_prep__remove_stopwords</th>\n",
       "      <th>param_prep__stem</th>\n",
       "      <th>param_vect</th>\n",
       "      <th>param_vect__min_df</th>\n",
       "      <th>param_vect__ngram_range</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.362904</td>\n",
       "      <td>0.025015</td>\n",
       "      <td>0.098400</td>\n",
       "      <td>0.013183</td>\n",
       "      <td>ComplementNB(alpha=1, class_prior=None, fit_pr...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>{'clf__estimator': ComplementNB(alpha=1, class...</td>\n",
       "      <td>0.878049</td>\n",
       "      <td>0.921875</td>\n",
       "      <td>0.934307</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.874074</td>\n",
       "      <td>0.909896</td>\n",
       "      <td>0.028338</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.341802</td>\n",
       "      <td>0.015815</td>\n",
       "      <td>0.084904</td>\n",
       "      <td>0.014674</td>\n",
       "      <td>ComplementNB(alpha=1, class_prior=None, fit_pr...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>TfidfVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>{'clf__estimator': ComplementNB(alpha=1, class...</td>\n",
       "      <td>0.878049</td>\n",
       "      <td>0.921875</td>\n",
       "      <td>0.934307</td>\n",
       "      <td>0.927536</td>\n",
       "      <td>0.874074</td>\n",
       "      <td>0.907168</td>\n",
       "      <td>0.025732</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.334402</td>\n",
       "      <td>0.021631</td>\n",
       "      <td>0.098600</td>\n",
       "      <td>0.018833</td>\n",
       "      <td>MultinomialNB(alpha=1, class_prior=None, fit_p...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>{'clf__estimator': MultinomialNB(alpha=1, clas...</td>\n",
       "      <td>0.878049</td>\n",
       "      <td>0.921875</td>\n",
       "      <td>0.934307</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.865672</td>\n",
       "      <td>0.906647</td>\n",
       "      <td>0.029003</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.342602</td>\n",
       "      <td>0.024484</td>\n",
       "      <td>0.075999</td>\n",
       "      <td>0.007155</td>\n",
       "      <td>ComplementNB(alpha=1, class_prior=None, fit_pr...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>{'clf__estimator': ComplementNB(alpha=1, class...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.921875</td>\n",
       "      <td>0.949640</td>\n",
       "      <td>0.918519</td>\n",
       "      <td>0.867647</td>\n",
       "      <td>0.905730</td>\n",
       "      <td>0.031658</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.384505</td>\n",
       "      <td>0.035630</td>\n",
       "      <td>0.098209</td>\n",
       "      <td>0.014511</td>\n",
       "      <td>SGDClassifier(alpha=0.001, average=False, clas...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>TfidfVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>{'clf__estimator': SGDClassifier(alpha=0.001, ...</td>\n",
       "      <td>0.898305</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.949640</td>\n",
       "      <td>0.926471</td>\n",
       "      <td>0.854962</td>\n",
       "      <td>0.903653</td>\n",
       "      <td>0.032413</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.366143</td>\n",
       "      <td>0.056360</td>\n",
       "      <td>0.071713</td>\n",
       "      <td>0.006905</td>\n",
       "      <td>SGDClassifier(alpha=0.001, average=False, clas...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>TfidfVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>{'clf__estimator': SGDClassifier(alpha=0.001, ...</td>\n",
       "      <td>0.898305</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.949640</td>\n",
       "      <td>0.926471</td>\n",
       "      <td>0.854962</td>\n",
       "      <td>0.903653</td>\n",
       "      <td>0.032413</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.360001</td>\n",
       "      <td>0.029714</td>\n",
       "      <td>0.095999</td>\n",
       "      <td>0.024788</td>\n",
       "      <td>LinearSVC(C=1000, class_weight=None, dual=True...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>TfidfVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>{'clf__estimator': LinearSVC(C=1000, class_wei...</td>\n",
       "      <td>0.905983</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.949640</td>\n",
       "      <td>0.926471</td>\n",
       "      <td>0.854962</td>\n",
       "      <td>0.903411</td>\n",
       "      <td>0.033379</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.367410</td>\n",
       "      <td>0.028748</td>\n",
       "      <td>0.078399</td>\n",
       "      <td>0.004128</td>\n",
       "      <td>ComplementNB(alpha=0.1, class_prior=None, fit_...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>TfidfVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>{'clf__estimator': ComplementNB(alpha=0.1, cla...</td>\n",
       "      <td>0.861789</td>\n",
       "      <td>0.921875</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>0.920863</td>\n",
       "      <td>0.865672</td>\n",
       "      <td>0.902611</td>\n",
       "      <td>0.032726</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.417515</td>\n",
       "      <td>0.029686</td>\n",
       "      <td>0.099799</td>\n",
       "      <td>0.016545</td>\n",
       "      <td>ComplementNB(alpha=1, class_prior=None, fit_pr...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>TfidfVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>{'clf__estimator': ComplementNB(alpha=1, class...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.921875</td>\n",
       "      <td>0.949640</td>\n",
       "      <td>0.911765</td>\n",
       "      <td>0.874074</td>\n",
       "      <td>0.902439</td>\n",
       "      <td>0.033950</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.463645</td>\n",
       "      <td>0.061681</td>\n",
       "      <td>0.126200</td>\n",
       "      <td>0.003709</td>\n",
       "      <td>MultinomialNB(alpha=1, class_prior=None, fit_p...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>TfidfVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>{'clf__estimator': MultinomialNB(alpha=1, clas...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.921875</td>\n",
       "      <td>0.918519</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.865672</td>\n",
       "      <td>0.902073</td>\n",
       "      <td>0.028044</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.394604</td>\n",
       "      <td>0.016450</td>\n",
       "      <td>0.111598</td>\n",
       "      <td>0.021322</td>\n",
       "      <td>MultinomialNB(alpha=1, class_prior=None, fit_p...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>{'clf__estimator': MultinomialNB(alpha=1, clas...</td>\n",
       "      <td>0.864000</td>\n",
       "      <td>0.921875</td>\n",
       "      <td>0.942029</td>\n",
       "      <td>0.910448</td>\n",
       "      <td>0.867647</td>\n",
       "      <td>0.901200</td>\n",
       "      <td>0.030626</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.321114</td>\n",
       "      <td>0.026670</td>\n",
       "      <td>0.092802</td>\n",
       "      <td>0.017267</td>\n",
       "      <td>SGDClassifier(alpha=0.001, average=False, clas...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>TfidfVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>{'clf__estimator': SGDClassifier(alpha=0.001, ...</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.957143</td>\n",
       "      <td>0.911765</td>\n",
       "      <td>0.865672</td>\n",
       "      <td>0.900694</td>\n",
       "      <td>0.031947</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "12       0.362904      0.025015         0.098400        0.013183   \n",
       "14       0.341802      0.015815         0.084904        0.014674   \n",
       "4        0.334402      0.021631         0.098600        0.018833   \n",
       "13       0.342602      0.024484         0.075999        0.007155   \n",
       "23       0.384505      0.035630         0.098209        0.014511   \n",
       "27       0.366143      0.056360         0.071713        0.006905   \n",
       "3        0.360001      0.029714         0.095999        0.024788   \n",
       "11       0.367410      0.028748         0.078399        0.004128   \n",
       "15       0.417515      0.029686         0.099799        0.016545   \n",
       "6        0.463645      0.061681         0.126200        0.003709   \n",
       "5        0.394604      0.016450         0.111598        0.021322   \n",
       "26       0.321114      0.026670         0.092802        0.017267   \n",
       "\n",
       "                                 param_clf__estimator  \\\n",
       "12  ComplementNB(alpha=1, class_prior=None, fit_pr...   \n",
       "14  ComplementNB(alpha=1, class_prior=None, fit_pr...   \n",
       "4   MultinomialNB(alpha=1, class_prior=None, fit_p...   \n",
       "13  ComplementNB(alpha=1, class_prior=None, fit_pr...   \n",
       "23  SGDClassifier(alpha=0.001, average=False, clas...   \n",
       "27  SGDClassifier(alpha=0.001, average=False, clas...   \n",
       "3   LinearSVC(C=1000, class_weight=None, dual=True...   \n",
       "11  ComplementNB(alpha=0.1, class_prior=None, fit_...   \n",
       "15  ComplementNB(alpha=1, class_prior=None, fit_pr...   \n",
       "6   MultinomialNB(alpha=1, class_prior=None, fit_p...   \n",
       "5   MultinomialNB(alpha=1, class_prior=None, fit_p...   \n",
       "26  SGDClassifier(alpha=0.001, average=False, clas...   \n",
       "\n",
       "   param_prep__remove_punctuation param_prep__remove_stopwords  \\\n",
       "12                           True                         True   \n",
       "14                           True                         True   \n",
       "4                            True                         True   \n",
       "13                           True                         True   \n",
       "23                           True                         True   \n",
       "27                           True                         True   \n",
       "3                            True                         True   \n",
       "11                           True                         True   \n",
       "15                           True                         True   \n",
       "6                            True                         True   \n",
       "5                            True                         True   \n",
       "26                           True                         True   \n",
       "\n",
       "   param_prep__stem                                         param_vect  \\\n",
       "12            False  CountVectorizer(analyzer='word', binary=False,...   \n",
       "14            False  TfidfVectorizer(analyzer='word', binary=False,...   \n",
       "4             False  CountVectorizer(analyzer='word', binary=False,...   \n",
       "13            False  CountVectorizer(analyzer='word', binary=False,...   \n",
       "23            False  TfidfVectorizer(analyzer='word', binary=False,...   \n",
       "27            False  TfidfVectorizer(analyzer='word', binary=False,...   \n",
       "3             False  TfidfVectorizer(analyzer='word', binary=False,...   \n",
       "11            False  TfidfVectorizer(analyzer='word', binary=False,...   \n",
       "15            False  TfidfVectorizer(analyzer='word', binary=False,...   \n",
       "6             False  TfidfVectorizer(analyzer='word', binary=False,...   \n",
       "5             False  CountVectorizer(analyzer='word', binary=False,...   \n",
       "26            False  TfidfVectorizer(analyzer='word', binary=False,...   \n",
       "\n",
       "   param_vect__min_df param_vect__ngram_range  \\\n",
       "12                  1                  (1, 1)   \n",
       "14                  1                  (1, 1)   \n",
       "4                   1                  (1, 1)   \n",
       "13                  1                  (1, 2)   \n",
       "23                  1                  (1, 2)   \n",
       "27                  1                  (1, 2)   \n",
       "3                   1                  (1, 2)   \n",
       "11                  1                  (1, 2)   \n",
       "15                  1                  (1, 2)   \n",
       "6                   1                  (1, 1)   \n",
       "5                   1                  (1, 2)   \n",
       "26                  1                  (1, 1)   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "12  {'clf__estimator': ComplementNB(alpha=1, class...           0.878049   \n",
       "14  {'clf__estimator': ComplementNB(alpha=1, class...           0.878049   \n",
       "4   {'clf__estimator': MultinomialNB(alpha=1, clas...           0.878049   \n",
       "13  {'clf__estimator': ComplementNB(alpha=1, class...           0.870968   \n",
       "23  {'clf__estimator': SGDClassifier(alpha=0.001, ...           0.898305   \n",
       "27  {'clf__estimator': SGDClassifier(alpha=0.001, ...           0.898305   \n",
       "3   {'clf__estimator': LinearSVC(C=1000, class_wei...           0.905983   \n",
       "11  {'clf__estimator': ComplementNB(alpha=0.1, cla...           0.861789   \n",
       "15  {'clf__estimator': ComplementNB(alpha=1, class...           0.854839   \n",
       "6   {'clf__estimator': MultinomialNB(alpha=1, clas...           0.870968   \n",
       "5   {'clf__estimator': MultinomialNB(alpha=1, clas...           0.864000   \n",
       "26  {'clf__estimator': SGDClassifier(alpha=0.001, ...           0.888889   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "12           0.921875           0.934307           0.941176   \n",
       "14           0.921875           0.934307           0.927536   \n",
       "4            0.921875           0.934307           0.933333   \n",
       "13           0.921875           0.949640           0.918519   \n",
       "23           0.888889           0.949640           0.926471   \n",
       "27           0.888889           0.949640           0.926471   \n",
       "3            0.880000           0.949640           0.926471   \n",
       "11           0.921875           0.942857           0.920863   \n",
       "15           0.921875           0.949640           0.911765   \n",
       "6            0.921875           0.918519           0.933333   \n",
       "5            0.921875           0.942029           0.910448   \n",
       "26           0.880000           0.957143           0.911765   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "12           0.874074         0.909896        0.028338                1  \n",
       "14           0.874074         0.907168        0.025732                2  \n",
       "4            0.865672         0.906647        0.029003                3  \n",
       "13           0.867647         0.905730        0.031658                4  \n",
       "23           0.854962         0.903653        0.032413                5  \n",
       "27           0.854962         0.903653        0.032413                5  \n",
       "3            0.854962         0.903411        0.033379                7  \n",
       "11           0.865672         0.902611        0.032726                8  \n",
       "15           0.874074         0.902439        0.033950                9  \n",
       "6            0.865672         0.902073        0.028044               10  \n",
       "5            0.867647         0.901200        0.030626               11  \n",
       "26           0.865672         0.900694        0.031947               12  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.sort_values(by=\"rank_test_score\", ascending=True).head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
