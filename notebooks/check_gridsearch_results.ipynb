{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T21:03:01.950645Z",
     "start_time": "2020-01-13T21:02:59.923647Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T21:03:18.910690Z",
     "start_time": "2020-01-13T21:03:02.719649Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lpesch\\AppData\\Local\\Continuum\\anaconda3\\envs\\fastai\\lib\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator LinearSVC from version 0.22 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "C:\\Users\\lpesch\\AppData\\Local\\Continuum\\anaconda3\\envs\\fastai\\lib\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator MultinomialNB from version 0.22 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "C:\\Users\\lpesch\\AppData\\Local\\Continuum\\anaconda3\\envs\\fastai\\lib\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator BernoulliNB from version 0.22 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "C:\\Users\\lpesch\\AppData\\Local\\Continuum\\anaconda3\\envs\\fastai\\lib\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator ComplementNB from version 0.22 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "C:\\Users\\lpesch\\AppData\\Local\\Continuum\\anaconda3\\envs\\fastai\\lib\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator SGDClassifier from version 0.22 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "C:\\Users\\lpesch\\AppData\\Local\\Continuum\\anaconda3\\envs\\fastai\\lib\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator CountVectorizer from version 0.22 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "C:\\Users\\lpesch\\AppData\\Local\\Continuum\\anaconda3\\envs\\fastai\\lib\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator TfidfTransformer from version 0.22 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "C:\\Users\\lpesch\\AppData\\Local\\Continuum\\anaconda3\\envs\\fastai\\lib\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator TfidfVectorizer from version 0.22 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "with open(\"..\\grid_search_results1.pck\", \"rb\") as f:\n",
    "    gridsearch_results = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T21:04:02.803854Z",
     "start_time": "2020-01-13T21:04:02.790857Z"
    }
   },
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(gridsearch_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T21:06:43.050698Z",
     "start_time": "2020-01-13T21:06:42.934700Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_clf__estimator</th>\n",
       "      <th>param_prep__remove_punctuation</th>\n",
       "      <th>param_prep__remove_stopwords</th>\n",
       "      <th>param_prep__stem</th>\n",
       "      <th>param_vect</th>\n",
       "      <th>param_vect__min_df</th>\n",
       "      <th>param_vect__ngram_range</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>0.520879</td>\n",
       "      <td>0.043216</td>\n",
       "      <td>0.106017</td>\n",
       "      <td>0.007377</td>\n",
       "      <td>ComplementNB(alpha=1, class_prior=None, fit_pr...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>{'clf__estimator': ComplementNB(alpha=1, class...</td>\n",
       "      <td>0.878049</td>\n",
       "      <td>0.921875</td>\n",
       "      <td>0.934307</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.874074</td>\n",
       "      <td>0.909896</td>\n",
       "      <td>0.028338</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>0.455213</td>\n",
       "      <td>0.041112</td>\n",
       "      <td>0.124323</td>\n",
       "      <td>0.009503</td>\n",
       "      <td>ComplementNB(alpha=1, class_prior=None, fit_pr...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>TfidfVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>{'clf__estimator': ComplementNB(alpha=1, class...</td>\n",
       "      <td>0.878049</td>\n",
       "      <td>0.921875</td>\n",
       "      <td>0.934307</td>\n",
       "      <td>0.927536</td>\n",
       "      <td>0.874074</td>\n",
       "      <td>0.907168</td>\n",
       "      <td>0.025732</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>0.474245</td>\n",
       "      <td>0.075823</td>\n",
       "      <td>0.112619</td>\n",
       "      <td>0.012110</td>\n",
       "      <td>MultinomialNB(alpha=1, class_prior=None, fit_p...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>{'clf__estimator': MultinomialNB(alpha=1, clas...</td>\n",
       "      <td>0.878049</td>\n",
       "      <td>0.921875</td>\n",
       "      <td>0.934307</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.865672</td>\n",
       "      <td>0.906647</td>\n",
       "      <td>0.029003</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>0.473410</td>\n",
       "      <td>0.015991</td>\n",
       "      <td>0.126799</td>\n",
       "      <td>0.019414</td>\n",
       "      <td>ComplementNB(alpha=1, class_prior=None, fit_pr...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>{'clf__estimator': ComplementNB(alpha=1, class...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.921875</td>\n",
       "      <td>0.949640</td>\n",
       "      <td>0.918519</td>\n",
       "      <td>0.867647</td>\n",
       "      <td>0.905730</td>\n",
       "      <td>0.031658</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>0.533226</td>\n",
       "      <td>0.034611</td>\n",
       "      <td>0.161427</td>\n",
       "      <td>0.019494</td>\n",
       "      <td>SGDClassifier(alpha=0.001, average=False, clas...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>TfidfVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>{'clf__estimator': SGDClassifier(alpha=0.001, ...</td>\n",
       "      <td>0.898305</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.949640</td>\n",
       "      <td>0.926471</td>\n",
       "      <td>0.854962</td>\n",
       "      <td>0.903653</td>\n",
       "      <td>0.032413</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.596400</td>\n",
       "      <td>0.049685</td>\n",
       "      <td>0.145401</td>\n",
       "      <td>0.026485</td>\n",
       "      <td>LinearSVC(C=1000, class_weight=None, dual=True...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>TfidfVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>{'clf__estimator': LinearSVC(C=1000, class_wei...</td>\n",
       "      <td>0.905983</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.949640</td>\n",
       "      <td>0.926471</td>\n",
       "      <td>0.854962</td>\n",
       "      <td>0.903411</td>\n",
       "      <td>0.033379</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>0.502803</td>\n",
       "      <td>0.030325</td>\n",
       "      <td>0.117400</td>\n",
       "      <td>0.014191</td>\n",
       "      <td>ComplementNB(alpha=0.01, class_prior=None, fit...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>TfidfVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>{'clf__estimator': ComplementNB(alpha=0.01, cl...</td>\n",
       "      <td>0.883333</td>\n",
       "      <td>0.906250</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.919708</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>0.903330</td>\n",
       "      <td>0.019576</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>0.669516</td>\n",
       "      <td>0.056399</td>\n",
       "      <td>0.155399</td>\n",
       "      <td>0.009436</td>\n",
       "      <td>ComplementNB(alpha=0.1, class_prior=None, fit_...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>TfidfVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>{'clf__estimator': ComplementNB(alpha=0.1, cla...</td>\n",
       "      <td>0.861789</td>\n",
       "      <td>0.921875</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>0.920863</td>\n",
       "      <td>0.865672</td>\n",
       "      <td>0.902611</td>\n",
       "      <td>0.032726</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>0.552249</td>\n",
       "      <td>0.032661</td>\n",
       "      <td>0.126400</td>\n",
       "      <td>0.024823</td>\n",
       "      <td>ComplementNB(alpha=1, class_prior=None, fit_pr...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>TfidfVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>{'clf__estimator': ComplementNB(alpha=1, class...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.921875</td>\n",
       "      <td>0.949640</td>\n",
       "      <td>0.911765</td>\n",
       "      <td>0.874074</td>\n",
       "      <td>0.902439</td>\n",
       "      <td>0.033950</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>0.382448</td>\n",
       "      <td>0.044997</td>\n",
       "      <td>0.094404</td>\n",
       "      <td>0.009955</td>\n",
       "      <td>MultinomialNB(alpha=1, class_prior=None, fit_p...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>TfidfVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>{'clf__estimator': MultinomialNB(alpha=1, clas...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.921875</td>\n",
       "      <td>0.918519</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.865672</td>\n",
       "      <td>0.902073</td>\n",
       "      <td>0.028044</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.541813</td>\n",
       "      <td>0.037327</td>\n",
       "      <td>0.178838</td>\n",
       "      <td>0.022898</td>\n",
       "      <td>MultinomialNB(alpha=0.01, class_prior=None, fi...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>TfidfVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>{'clf__estimator': MultinomialNB(alpha=0.01, c...</td>\n",
       "      <td>0.883333</td>\n",
       "      <td>0.897638</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.919708</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>0.901608</td>\n",
       "      <td>0.019622</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>0.519444</td>\n",
       "      <td>0.029682</td>\n",
       "      <td>0.131849</td>\n",
       "      <td>0.015933</td>\n",
       "      <td>MultinomialNB(alpha=1, class_prior=None, fit_p...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>{'clf__estimator': MultinomialNB(alpha=1, clas...</td>\n",
       "      <td>0.864000</td>\n",
       "      <td>0.921875</td>\n",
       "      <td>0.942029</td>\n",
       "      <td>0.910448</td>\n",
       "      <td>0.867647</td>\n",
       "      <td>0.901200</td>\n",
       "      <td>0.030626</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "444       0.520879      0.043216         0.106017        0.007377   \n",
       "450       0.455213      0.041112         0.124323        0.009503   \n",
       "156       0.474245      0.075823         0.112619        0.012110   \n",
       "445       0.473410      0.015991         0.126799        0.019414   \n",
       "499       0.533226      0.034611         0.161427        0.019494   \n",
       "19        0.596400      0.049685         0.145401        0.026485   \n",
       "355       0.502803      0.030325         0.117400        0.014191   \n",
       "403       0.669516      0.056399         0.155399        0.009436   \n",
       "451       0.552249      0.032661         0.126400        0.024823   \n",
       "162       0.382448      0.044997         0.094404        0.009955   \n",
       "67        0.541813      0.037327         0.178838        0.022898   \n",
       "157       0.519444      0.029682         0.131849        0.015933   \n",
       "\n",
       "                                  param_clf__estimator  \\\n",
       "444  ComplementNB(alpha=1, class_prior=None, fit_pr...   \n",
       "450  ComplementNB(alpha=1, class_prior=None, fit_pr...   \n",
       "156  MultinomialNB(alpha=1, class_prior=None, fit_p...   \n",
       "445  ComplementNB(alpha=1, class_prior=None, fit_pr...   \n",
       "499  SGDClassifier(alpha=0.001, average=False, clas...   \n",
       "19   LinearSVC(C=1000, class_weight=None, dual=True...   \n",
       "355  ComplementNB(alpha=0.01, class_prior=None, fit...   \n",
       "403  ComplementNB(alpha=0.1, class_prior=None, fit_...   \n",
       "451  ComplementNB(alpha=1, class_prior=None, fit_pr...   \n",
       "162  MultinomialNB(alpha=1, class_prior=None, fit_p...   \n",
       "67   MultinomialNB(alpha=0.01, class_prior=None, fi...   \n",
       "157  MultinomialNB(alpha=1, class_prior=None, fit_p...   \n",
       "\n",
       "    param_prep__remove_punctuation param_prep__remove_stopwords  \\\n",
       "444                           True                         True   \n",
       "450                           True                         True   \n",
       "156                           True                         True   \n",
       "445                           True                         True   \n",
       "499                           True                         True   \n",
       "19                            True                         True   \n",
       "355                           True                         True   \n",
       "403                           True                         True   \n",
       "451                           True                         True   \n",
       "162                           True                         True   \n",
       "67                            True                         True   \n",
       "157                           True                         True   \n",
       "\n",
       "    param_prep__stem                                         param_vect  \\\n",
       "444            False  CountVectorizer(analyzer='word', binary=False,...   \n",
       "450            False  TfidfVectorizer(analyzer='word', binary=False,...   \n",
       "156            False  CountVectorizer(analyzer='word', binary=False,...   \n",
       "445            False  CountVectorizer(analyzer='word', binary=False,...   \n",
       "499            False  TfidfVectorizer(analyzer='word', binary=False,...   \n",
       "19             False  TfidfVectorizer(analyzer='word', binary=False,...   \n",
       "355            False  TfidfVectorizer(analyzer='word', binary=False,...   \n",
       "403            False  TfidfVectorizer(analyzer='word', binary=False,...   \n",
       "451            False  TfidfVectorizer(analyzer='word', binary=False,...   \n",
       "162            False  TfidfVectorizer(analyzer='word', binary=False,...   \n",
       "67             False  TfidfVectorizer(analyzer='word', binary=False,...   \n",
       "157            False  CountVectorizer(analyzer='word', binary=False,...   \n",
       "\n",
       "    param_vect__min_df param_vect__ngram_range  \\\n",
       "444                  1                  (1, 1)   \n",
       "450                  1                  (1, 1)   \n",
       "156                  1                  (1, 1)   \n",
       "445                  1                  (1, 2)   \n",
       "499                  1                  (1, 2)   \n",
       "19                   1                  (1, 2)   \n",
       "355                  1                  (1, 2)   \n",
       "403                  1                  (1, 2)   \n",
       "451                  1                  (1, 2)   \n",
       "162                  1                  (1, 1)   \n",
       "67                   1                  (1, 2)   \n",
       "157                  1                  (1, 2)   \n",
       "\n",
       "                                                params  split0_test_score  \\\n",
       "444  {'clf__estimator': ComplementNB(alpha=1, class...           0.878049   \n",
       "450  {'clf__estimator': ComplementNB(alpha=1, class...           0.878049   \n",
       "156  {'clf__estimator': MultinomialNB(alpha=1, clas...           0.878049   \n",
       "445  {'clf__estimator': ComplementNB(alpha=1, class...           0.870968   \n",
       "499  {'clf__estimator': SGDClassifier(alpha=0.001, ...           0.898305   \n",
       "19   {'clf__estimator': LinearSVC(C=1000, class_wei...           0.905983   \n",
       "355  {'clf__estimator': ComplementNB(alpha=0.01, cl...           0.883333   \n",
       "403  {'clf__estimator': ComplementNB(alpha=0.1, cla...           0.861789   \n",
       "451  {'clf__estimator': ComplementNB(alpha=1, class...           0.854839   \n",
       "162  {'clf__estimator': MultinomialNB(alpha=1, clas...           0.870968   \n",
       "67   {'clf__estimator': MultinomialNB(alpha=0.01, c...           0.883333   \n",
       "157  {'clf__estimator': MultinomialNB(alpha=1, clas...           0.864000   \n",
       "\n",
       "     split1_test_score  split2_test_score  split3_test_score  \\\n",
       "444           0.921875           0.934307           0.941176   \n",
       "450           0.921875           0.934307           0.927536   \n",
       "156           0.921875           0.934307           0.933333   \n",
       "445           0.921875           0.949640           0.918519   \n",
       "499           0.888889           0.949640           0.926471   \n",
       "19            0.880000           0.949640           0.926471   \n",
       "355           0.906250           0.928571           0.919708   \n",
       "403           0.921875           0.942857           0.920863   \n",
       "451           0.921875           0.949640           0.911765   \n",
       "162           0.921875           0.918519           0.933333   \n",
       "67            0.897638           0.928571           0.919708   \n",
       "157           0.921875           0.942029           0.910448   \n",
       "\n",
       "     split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "444           0.874074         0.909896        0.028338                1  \n",
       "450           0.874074         0.907168        0.025732                2  \n",
       "156           0.865672         0.906647        0.029003                3  \n",
       "445           0.867647         0.905730        0.031658                4  \n",
       "499           0.854962         0.903653        0.032413                5  \n",
       "19            0.854962         0.903411        0.033379                6  \n",
       "355           0.878788         0.903330        0.019576                7  \n",
       "403           0.865672         0.902611        0.032726                8  \n",
       "451           0.874074         0.902439        0.033950                9  \n",
       "162           0.865672         0.902073        0.028044               10  \n",
       "67            0.878788         0.901608        0.019622               11  \n",
       "157           0.867647         0.901200        0.030626               12  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.sort_values(by=\"rank_test_score\", ascending=True).head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T21:21:03.783834Z",
     "start_time": "2020-01-13T21:21:03.770837Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lpesch\\AppData\\Local\\Continuum\\anaconda3\\envs\\fastai\\lib\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator LinearSVC from version 0.22 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "C:\\Users\\lpesch\\AppData\\Local\\Continuum\\anaconda3\\envs\\fastai\\lib\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator MultinomialNB from version 0.22 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "C:\\Users\\lpesch\\AppData\\Local\\Continuum\\anaconda3\\envs\\fastai\\lib\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator ComplementNB from version 0.22 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "C:\\Users\\lpesch\\AppData\\Local\\Continuum\\anaconda3\\envs\\fastai\\lib\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator SGDClassifier from version 0.22 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "C:\\Users\\lpesch\\AppData\\Local\\Continuum\\anaconda3\\envs\\fastai\\lib\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator CountVectorizer from version 0.22 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "C:\\Users\\lpesch\\AppData\\Local\\Continuum\\anaconda3\\envs\\fastai\\lib\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator TfidfTransformer from version 0.22 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "C:\\Users\\lpesch\\AppData\\Local\\Continuum\\anaconda3\\envs\\fastai\\lib\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator TfidfVectorizer from version 0.22 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "with open(\"..\\grid_search_results2.pck\", \"rb\") as f:\n",
    "    gridsearch_results = pickle.load(f)\n",
    "df2 = pd.DataFrame(gridsearch_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T21:21:07.697834Z",
     "start_time": "2020-01-13T21:21:07.568834Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_clf__estimator</th>\n",
       "      <th>param_prep__remove_punctuation</th>\n",
       "      <th>param_prep__remove_stopwords</th>\n",
       "      <th>param_prep__stem</th>\n",
       "      <th>param_vect</th>\n",
       "      <th>param_vect__min_df</th>\n",
       "      <th>param_vect__ngram_range</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.362904</td>\n",
       "      <td>0.025015</td>\n",
       "      <td>0.098400</td>\n",
       "      <td>0.013183</td>\n",
       "      <td>ComplementNB(alpha=1, class_prior=None, fit_pr...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>{'clf__estimator': ComplementNB(alpha=1, class...</td>\n",
       "      <td>0.878049</td>\n",
       "      <td>0.921875</td>\n",
       "      <td>0.934307</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.874074</td>\n",
       "      <td>0.909896</td>\n",
       "      <td>0.028338</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.341802</td>\n",
       "      <td>0.015815</td>\n",
       "      <td>0.084904</td>\n",
       "      <td>0.014674</td>\n",
       "      <td>ComplementNB(alpha=1, class_prior=None, fit_pr...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>TfidfVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>{'clf__estimator': ComplementNB(alpha=1, class...</td>\n",
       "      <td>0.878049</td>\n",
       "      <td>0.921875</td>\n",
       "      <td>0.934307</td>\n",
       "      <td>0.927536</td>\n",
       "      <td>0.874074</td>\n",
       "      <td>0.907168</td>\n",
       "      <td>0.025732</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.334402</td>\n",
       "      <td>0.021631</td>\n",
       "      <td>0.098600</td>\n",
       "      <td>0.018833</td>\n",
       "      <td>MultinomialNB(alpha=1, class_prior=None, fit_p...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>{'clf__estimator': MultinomialNB(alpha=1, clas...</td>\n",
       "      <td>0.878049</td>\n",
       "      <td>0.921875</td>\n",
       "      <td>0.934307</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.865672</td>\n",
       "      <td>0.906647</td>\n",
       "      <td>0.029003</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.342602</td>\n",
       "      <td>0.024484</td>\n",
       "      <td>0.075999</td>\n",
       "      <td>0.007155</td>\n",
       "      <td>ComplementNB(alpha=1, class_prior=None, fit_pr...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>{'clf__estimator': ComplementNB(alpha=1, class...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.921875</td>\n",
       "      <td>0.949640</td>\n",
       "      <td>0.918519</td>\n",
       "      <td>0.867647</td>\n",
       "      <td>0.905730</td>\n",
       "      <td>0.031658</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.384505</td>\n",
       "      <td>0.035630</td>\n",
       "      <td>0.098209</td>\n",
       "      <td>0.014511</td>\n",
       "      <td>SGDClassifier(alpha=0.001, average=False, clas...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>TfidfVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>{'clf__estimator': SGDClassifier(alpha=0.001, ...</td>\n",
       "      <td>0.898305</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.949640</td>\n",
       "      <td>0.926471</td>\n",
       "      <td>0.854962</td>\n",
       "      <td>0.903653</td>\n",
       "      <td>0.032413</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.366143</td>\n",
       "      <td>0.056360</td>\n",
       "      <td>0.071713</td>\n",
       "      <td>0.006905</td>\n",
       "      <td>SGDClassifier(alpha=0.001, average=False, clas...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>TfidfVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>{'clf__estimator': SGDClassifier(alpha=0.001, ...</td>\n",
       "      <td>0.898305</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.949640</td>\n",
       "      <td>0.926471</td>\n",
       "      <td>0.854962</td>\n",
       "      <td>0.903653</td>\n",
       "      <td>0.032413</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.360001</td>\n",
       "      <td>0.029714</td>\n",
       "      <td>0.095999</td>\n",
       "      <td>0.024788</td>\n",
       "      <td>LinearSVC(C=1000, class_weight=None, dual=True...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>TfidfVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>{'clf__estimator': LinearSVC(C=1000, class_wei...</td>\n",
       "      <td>0.905983</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.949640</td>\n",
       "      <td>0.926471</td>\n",
       "      <td>0.854962</td>\n",
       "      <td>0.903411</td>\n",
       "      <td>0.033379</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.367410</td>\n",
       "      <td>0.028748</td>\n",
       "      <td>0.078399</td>\n",
       "      <td>0.004128</td>\n",
       "      <td>ComplementNB(alpha=0.1, class_prior=None, fit_...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>TfidfVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>{'clf__estimator': ComplementNB(alpha=0.1, cla...</td>\n",
       "      <td>0.861789</td>\n",
       "      <td>0.921875</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>0.920863</td>\n",
       "      <td>0.865672</td>\n",
       "      <td>0.902611</td>\n",
       "      <td>0.032726</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.417515</td>\n",
       "      <td>0.029686</td>\n",
       "      <td>0.099799</td>\n",
       "      <td>0.016545</td>\n",
       "      <td>ComplementNB(alpha=1, class_prior=None, fit_pr...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>TfidfVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>{'clf__estimator': ComplementNB(alpha=1, class...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.921875</td>\n",
       "      <td>0.949640</td>\n",
       "      <td>0.911765</td>\n",
       "      <td>0.874074</td>\n",
       "      <td>0.902439</td>\n",
       "      <td>0.033950</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.463645</td>\n",
       "      <td>0.061681</td>\n",
       "      <td>0.126200</td>\n",
       "      <td>0.003709</td>\n",
       "      <td>MultinomialNB(alpha=1, class_prior=None, fit_p...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>TfidfVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>{'clf__estimator': MultinomialNB(alpha=1, clas...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.921875</td>\n",
       "      <td>0.918519</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.865672</td>\n",
       "      <td>0.902073</td>\n",
       "      <td>0.028044</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.394604</td>\n",
       "      <td>0.016450</td>\n",
       "      <td>0.111598</td>\n",
       "      <td>0.021322</td>\n",
       "      <td>MultinomialNB(alpha=1, class_prior=None, fit_p...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>{'clf__estimator': MultinomialNB(alpha=1, clas...</td>\n",
       "      <td>0.864000</td>\n",
       "      <td>0.921875</td>\n",
       "      <td>0.942029</td>\n",
       "      <td>0.910448</td>\n",
       "      <td>0.867647</td>\n",
       "      <td>0.901200</td>\n",
       "      <td>0.030626</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.321114</td>\n",
       "      <td>0.026670</td>\n",
       "      <td>0.092802</td>\n",
       "      <td>0.017267</td>\n",
       "      <td>SGDClassifier(alpha=0.001, average=False, clas...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>TfidfVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>{'clf__estimator': SGDClassifier(alpha=0.001, ...</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.957143</td>\n",
       "      <td>0.911765</td>\n",
       "      <td>0.865672</td>\n",
       "      <td>0.900694</td>\n",
       "      <td>0.031947</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "12       0.362904      0.025015         0.098400        0.013183   \n",
       "14       0.341802      0.015815         0.084904        0.014674   \n",
       "4        0.334402      0.021631         0.098600        0.018833   \n",
       "13       0.342602      0.024484         0.075999        0.007155   \n",
       "23       0.384505      0.035630         0.098209        0.014511   \n",
       "27       0.366143      0.056360         0.071713        0.006905   \n",
       "3        0.360001      0.029714         0.095999        0.024788   \n",
       "11       0.367410      0.028748         0.078399        0.004128   \n",
       "15       0.417515      0.029686         0.099799        0.016545   \n",
       "6        0.463645      0.061681         0.126200        0.003709   \n",
       "5        0.394604      0.016450         0.111598        0.021322   \n",
       "26       0.321114      0.026670         0.092802        0.017267   \n",
       "\n",
       "                                 param_clf__estimator  \\\n",
       "12  ComplementNB(alpha=1, class_prior=None, fit_pr...   \n",
       "14  ComplementNB(alpha=1, class_prior=None, fit_pr...   \n",
       "4   MultinomialNB(alpha=1, class_prior=None, fit_p...   \n",
       "13  ComplementNB(alpha=1, class_prior=None, fit_pr...   \n",
       "23  SGDClassifier(alpha=0.001, average=False, clas...   \n",
       "27  SGDClassifier(alpha=0.001, average=False, clas...   \n",
       "3   LinearSVC(C=1000, class_weight=None, dual=True...   \n",
       "11  ComplementNB(alpha=0.1, class_prior=None, fit_...   \n",
       "15  ComplementNB(alpha=1, class_prior=None, fit_pr...   \n",
       "6   MultinomialNB(alpha=1, class_prior=None, fit_p...   \n",
       "5   MultinomialNB(alpha=1, class_prior=None, fit_p...   \n",
       "26  SGDClassifier(alpha=0.001, average=False, clas...   \n",
       "\n",
       "   param_prep__remove_punctuation param_prep__remove_stopwords  \\\n",
       "12                           True                         True   \n",
       "14                           True                         True   \n",
       "4                            True                         True   \n",
       "13                           True                         True   \n",
       "23                           True                         True   \n",
       "27                           True                         True   \n",
       "3                            True                         True   \n",
       "11                           True                         True   \n",
       "15                           True                         True   \n",
       "6                            True                         True   \n",
       "5                            True                         True   \n",
       "26                           True                         True   \n",
       "\n",
       "   param_prep__stem                                         param_vect  \\\n",
       "12            False  CountVectorizer(analyzer='word', binary=False,...   \n",
       "14            False  TfidfVectorizer(analyzer='word', binary=False,...   \n",
       "4             False  CountVectorizer(analyzer='word', binary=False,...   \n",
       "13            False  CountVectorizer(analyzer='word', binary=False,...   \n",
       "23            False  TfidfVectorizer(analyzer='word', binary=False,...   \n",
       "27            False  TfidfVectorizer(analyzer='word', binary=False,...   \n",
       "3             False  TfidfVectorizer(analyzer='word', binary=False,...   \n",
       "11            False  TfidfVectorizer(analyzer='word', binary=False,...   \n",
       "15            False  TfidfVectorizer(analyzer='word', binary=False,...   \n",
       "6             False  TfidfVectorizer(analyzer='word', binary=False,...   \n",
       "5             False  CountVectorizer(analyzer='word', binary=False,...   \n",
       "26            False  TfidfVectorizer(analyzer='word', binary=False,...   \n",
       "\n",
       "   param_vect__min_df param_vect__ngram_range  \\\n",
       "12                  1                  (1, 1)   \n",
       "14                  1                  (1, 1)   \n",
       "4                   1                  (1, 1)   \n",
       "13                  1                  (1, 2)   \n",
       "23                  1                  (1, 2)   \n",
       "27                  1                  (1, 2)   \n",
       "3                   1                  (1, 2)   \n",
       "11                  1                  (1, 2)   \n",
       "15                  1                  (1, 2)   \n",
       "6                   1                  (1, 1)   \n",
       "5                   1                  (1, 2)   \n",
       "26                  1                  (1, 1)   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "12  {'clf__estimator': ComplementNB(alpha=1, class...           0.878049   \n",
       "14  {'clf__estimator': ComplementNB(alpha=1, class...           0.878049   \n",
       "4   {'clf__estimator': MultinomialNB(alpha=1, clas...           0.878049   \n",
       "13  {'clf__estimator': ComplementNB(alpha=1, class...           0.870968   \n",
       "23  {'clf__estimator': SGDClassifier(alpha=0.001, ...           0.898305   \n",
       "27  {'clf__estimator': SGDClassifier(alpha=0.001, ...           0.898305   \n",
       "3   {'clf__estimator': LinearSVC(C=1000, class_wei...           0.905983   \n",
       "11  {'clf__estimator': ComplementNB(alpha=0.1, cla...           0.861789   \n",
       "15  {'clf__estimator': ComplementNB(alpha=1, class...           0.854839   \n",
       "6   {'clf__estimator': MultinomialNB(alpha=1, clas...           0.870968   \n",
       "5   {'clf__estimator': MultinomialNB(alpha=1, clas...           0.864000   \n",
       "26  {'clf__estimator': SGDClassifier(alpha=0.001, ...           0.888889   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "12           0.921875           0.934307           0.941176   \n",
       "14           0.921875           0.934307           0.927536   \n",
       "4            0.921875           0.934307           0.933333   \n",
       "13           0.921875           0.949640           0.918519   \n",
       "23           0.888889           0.949640           0.926471   \n",
       "27           0.888889           0.949640           0.926471   \n",
       "3            0.880000           0.949640           0.926471   \n",
       "11           0.921875           0.942857           0.920863   \n",
       "15           0.921875           0.949640           0.911765   \n",
       "6            0.921875           0.918519           0.933333   \n",
       "5            0.921875           0.942029           0.910448   \n",
       "26           0.880000           0.957143           0.911765   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "12           0.874074         0.909896        0.028338                1  \n",
       "14           0.874074         0.907168        0.025732                2  \n",
       "4            0.865672         0.906647        0.029003                3  \n",
       "13           0.867647         0.905730        0.031658                4  \n",
       "23           0.854962         0.903653        0.032413                5  \n",
       "27           0.854962         0.903653        0.032413                5  \n",
       "3            0.854962         0.903411        0.033379                7  \n",
       "11           0.865672         0.902611        0.032726                8  \n",
       "15           0.874074         0.902439        0.033950                9  \n",
       "6            0.865672         0.902073        0.028044               10  \n",
       "5            0.867647         0.901200        0.030626               11  \n",
       "26           0.865672         0.900694        0.031947               12  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.sort_values(by=\"rank_test_score\", ascending=True).head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
